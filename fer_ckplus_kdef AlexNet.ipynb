{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc648f39-57a6-4594-9cbe-911585286e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32854\n",
      "32854\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/default/miniconda3/envs/mne/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "file_paths = [] # an empty list to store the file paths\n",
    "labels = [] # an empty list to store the labels\n",
    "for path in Path('fer_ckplus_kdef').rglob('*.png'): # loop through all png files in the dataset folder and its subfolders\n",
    "    file_paths.append(str(path)) # append the file path as a string to the list\n",
    "    labels.append(path.parent.name) # append the folder name as the label to the list\n",
    "print(len(file_paths))\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "labels = np.array(labels).reshape(-1, 1)\n",
    "labels = enc.fit_transform(labels)\n",
    "print(len(labels))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "924fd99c-93b9-4ac9-b68d-49dffed7781b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(\n",
    "    file_paths, labels, test_size=0.125, random_state=42, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da876b46-ab43-4f8c-8156-4ddffe6e7704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-07 16:32:39.832332: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-07 16:32:40.938896: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import math\n",
    "class ImageSequence(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.x) / self.batch_size)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        low = idx * self.batch_size\n",
    "        # Cap upper bound at array length; the last batch may be smaller\n",
    "        # if the total number of items is not a multiple of batch size.\n",
    "        high = min(low + self.batch_size, len(self.x))\n",
    "        batch_x = self.x[low:high]\n",
    "        batch_y = self.y[low:high]\n",
    "\n",
    "        return np.array([np.array(Image.open(file_name)) / 255.0 for file_name in batch_x]), np.array(batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2459b99d-3d03-4726-9f9d-62cec6e78b5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,BatchNormalization,Dense,Dropout,Flatten,Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras import optimizers\n",
    "num_classes = 8\n",
    "def AlexNet():\n",
    "    model = Sequential()\n",
    "    clear_session()\n",
    "    #Conv2D 1\n",
    "    model.add(Input((224, 224, 1)))\n",
    "    model.add(Conv2D(96, 11, strides=(4, 4), padding='valid', activation='relu')) \n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    #Conv2D 2\n",
    "    model.add(Conv2D(256, 5, strides=(1, 1), padding='same', activation='relu')) \n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    #Conv2D 3 4 5\n",
    "    model.add(Conv2D(384, 3, strides=(1, 1), padding='same', activation='relu')) \n",
    "    model.add(Conv2D(384, 3, strides=(1, 1), padding='same', activation='relu')) \n",
    "    model.add(Conv2D(256, 3, strides=(1, 1), padding='same', activation='relu')) \n",
    "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2,2)))\n",
    "    model.add(BatchNormalization())\n",
    "    #Dense 1\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    #Dense 2\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    #Dense 3\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile('sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = AlexNet()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0fc9e740-6a86-4287-bfea-7f5e38d89138",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "225/225 [==============================] - 30s 123ms/step - loss: 2.0769 - accuracy: 0.2664 - val_loss: 1.7997 - val_accuracy: 0.3002 - lr: 0.0100\n",
      "Epoch 2/50\n",
      "225/225 [==============================] - 24s 107ms/step - loss: 1.6941 - accuracy: 0.3672 - val_loss: 1.5930 - val_accuracy: 0.4076 - lr: 0.0100\n",
      "Epoch 3/50\n",
      "225/225 [==============================] - 24s 108ms/step - loss: 1.5237 - accuracy: 0.4321 - val_loss: 1.4187 - val_accuracy: 0.4787 - lr: 0.0100\n",
      "Epoch 4/50\n",
      "225/225 [==============================] - 24s 108ms/step - loss: 1.4062 - accuracy: 0.4746 - val_loss: 1.4356 - val_accuracy: 0.4599 - lr: 0.0100\n",
      "Epoch 5/50\n",
      "225/225 [==============================] - 24s 108ms/step - loss: 1.3125 - accuracy: 0.5095 - val_loss: 1.3308 - val_accuracy: 0.5116 - lr: 0.0100\n",
      "Epoch 6/50\n",
      "225/225 [==============================] - 24s 108ms/step - loss: 1.2271 - accuracy: 0.5406 - val_loss: 1.2620 - val_accuracy: 0.5398 - lr: 0.0100\n",
      "Epoch 7/50\n",
      "225/225 [==============================] - 25s 109ms/step - loss: 1.1523 - accuracy: 0.5724 - val_loss: 1.2459 - val_accuracy: 0.5449 - lr: 0.0100\n",
      "Epoch 8/50\n",
      "225/225 [==============================] - 25s 109ms/step - loss: 1.0868 - accuracy: 0.5980 - val_loss: 1.1839 - val_accuracy: 0.5754 - lr: 0.0100\n",
      "Epoch 9/50\n",
      "225/225 [==============================] - 25s 109ms/step - loss: 1.0296 - accuracy: 0.6260 - val_loss: 1.1059 - val_accuracy: 0.6048 - lr: 0.0100\n",
      "Epoch 10/50\n",
      "225/225 [==============================] - 25s 109ms/step - loss: 0.9767 - accuracy: 0.6390 - val_loss: 1.0536 - val_accuracy: 0.6238 - lr: 0.0100\n",
      "Epoch 11/50\n",
      "225/225 [==============================] - 25s 109ms/step - loss: 0.9298 - accuracy: 0.6625 - val_loss: 1.0432 - val_accuracy: 0.6255 - lr: 0.0100\n",
      "Epoch 12/50\n",
      "225/225 [==============================] - 25s 109ms/step - loss: 0.8781 - accuracy: 0.6788 - val_loss: 1.0295 - val_accuracy: 0.6297 - lr: 0.0100\n",
      "Epoch 13/50\n",
      "225/225 [==============================] - 25s 109ms/step - loss: 0.8310 - accuracy: 0.6967 - val_loss: 1.0502 - val_accuracy: 0.6277 - lr: 0.0100\n",
      "Epoch 14/50\n",
      "225/225 [==============================] - 25s 110ms/step - loss: 0.7878 - accuracy: 0.7140 - val_loss: 1.0715 - val_accuracy: 0.6170 - lr: 0.0100\n",
      "Epoch 15/50\n",
      "225/225 [==============================] - 25s 110ms/step - loss: 0.7378 - accuracy: 0.7327 - val_loss: 1.0145 - val_accuracy: 0.6445 - lr: 0.0100\n",
      "Epoch 16/50\n",
      "225/225 [==============================] - 25s 111ms/step - loss: 0.6960 - accuracy: 0.7474 - val_loss: 0.9582 - val_accuracy: 0.6620 - lr: 0.0100\n",
      "Epoch 17/50\n",
      "225/225 [==============================] - 25s 110ms/step - loss: 0.6438 - accuracy: 0.7668 - val_loss: 1.0097 - val_accuracy: 0.6530 - lr: 0.0100\n",
      "Epoch 18/50\n",
      "225/225 [==============================] - 25s 110ms/step - loss: 0.5960 - accuracy: 0.7855 - val_loss: 0.9961 - val_accuracy: 0.6477 - lr: 0.0100\n",
      "Epoch 19/50\n",
      "225/225 [==============================] - 25s 110ms/step - loss: 0.5531 - accuracy: 0.8010 - val_loss: 1.0373 - val_accuracy: 0.6586 - lr: 0.0100\n",
      "Epoch 20/50\n",
      "225/225 [==============================] - 25s 110ms/step - loss: 0.5085 - accuracy: 0.8174 - val_loss: 1.1114 - val_accuracy: 0.6499 - lr: 0.0100\n",
      "Epoch 21/50\n",
      "225/225 [==============================] - 25s 110ms/step - loss: 0.4578 - accuracy: 0.8366 - val_loss: 1.2386 - val_accuracy: 0.6255 - lr: 0.0100\n",
      "Epoch 22/50\n",
      "225/225 [==============================] - 25s 109ms/step - loss: 0.4201 - accuracy: 0.8511 - val_loss: 1.0944 - val_accuracy: 0.6474 - lr: 0.0100\n",
      "Epoch 23/50\n",
      "225/225 [==============================] - 25s 110ms/step - loss: 0.3766 - accuracy: 0.8689 - val_loss: 1.1239 - val_accuracy: 0.6484 - lr: 0.0100\n",
      "Epoch 24/50\n",
      "225/225 [==============================] - 25s 109ms/step - loss: 0.3455 - accuracy: 0.8776 - val_loss: 1.1257 - val_accuracy: 0.6633 - lr: 0.0100\n",
      "Epoch 25/50\n",
      "225/225 [==============================] - 25s 109ms/step - loss: 0.3040 - accuracy: 0.8932 - val_loss: 1.1912 - val_accuracy: 0.6657 - lr: 0.0100\n",
      "Epoch 26/50\n",
      "225/225 [==============================] - 25s 110ms/step - loss: 0.2729 - accuracy: 0.9066 - val_loss: 1.1531 - val_accuracy: 0.6752 - lr: 0.0100\n",
      "Epoch 27/50\n",
      "225/225 [==============================] - 25s 110ms/step - loss: 0.1580 - accuracy: 0.9497 - val_loss: 1.1682 - val_accuracy: 0.6876 - lr: 0.0050\n",
      "Epoch 28/50\n",
      "225/225 [==============================] - 25s 110ms/step - loss: 0.1228 - accuracy: 0.9631 - val_loss: 1.2315 - val_accuracy: 0.6859 - lr: 0.0050\n",
      "Epoch 29/50\n",
      "225/225 [==============================] - 25s 110ms/step - loss: 0.1001 - accuracy: 0.9716 - val_loss: 1.3165 - val_accuracy: 0.6869 - lr: 0.0050\n",
      "Epoch 30/50\n",
      "225/225 [==============================] - 26s 114ms/step - loss: 0.0887 - accuracy: 0.9750 - val_loss: 1.2766 - val_accuracy: 0.6964 - lr: 0.0050\n",
      "Epoch 31/50\n",
      "225/225 [==============================] - 25s 112ms/step - loss: 0.0778 - accuracy: 0.9792 - val_loss: 1.3487 - val_accuracy: 0.6947 - lr: 0.0050\n",
      "Epoch 32/50\n",
      "225/225 [==============================] - 25s 110ms/step - loss: 0.0706 - accuracy: 0.9807 - val_loss: 1.3417 - val_accuracy: 0.6878 - lr: 0.0050\n",
      "Epoch 33/50\n",
      "225/225 [==============================] - 25s 111ms/step - loss: 0.0659 - accuracy: 0.9822 - val_loss: 1.3622 - val_accuracy: 0.6959 - lr: 0.0050\n",
      "Epoch 34/50\n",
      "225/225 [==============================] - 25s 111ms/step - loss: 0.0621 - accuracy: 0.9834 - val_loss: 1.4477 - val_accuracy: 0.6878 - lr: 0.0050\n",
      "Epoch 35/50\n",
      "225/225 [==============================] - 25s 110ms/step - loss: 0.0599 - accuracy: 0.9837 - val_loss: 1.4728 - val_accuracy: 0.6915 - lr: 0.0050\n",
      "Epoch 36/50\n",
      "225/225 [==============================] - 25s 110ms/step - loss: 0.0543 - accuracy: 0.9854 - val_loss: 1.4800 - val_accuracy: 0.6939 - lr: 0.0050\n",
      "Epoch 37/50\n",
      "225/225 [==============================] - 25s 110ms/step - loss: 0.0390 - accuracy: 0.9906 - val_loss: 1.4384 - val_accuracy: 0.6976 - lr: 0.0025\n",
      "Epoch 38/50\n",
      "225/225 [==============================] - 25s 110ms/step - loss: 0.0329 - accuracy: 0.9922 - val_loss: 1.4830 - val_accuracy: 0.6961 - lr: 0.0025\n",
      "Epoch 39/50\n",
      "225/225 [==============================] - 25s 110ms/step - loss: 0.0291 - accuracy: 0.9929 - val_loss: 1.4933 - val_accuracy: 0.6973 - lr: 0.0025\n",
      "Epoch 40/50\n",
      "225/225 [==============================] - 25s 113ms/step - loss: 0.0297 - accuracy: 0.9931 - val_loss: 1.4967 - val_accuracy: 0.6954 - lr: 0.0025\n",
      "Epoch 41/50\n",
      "225/225 [==============================] - 25s 111ms/step - loss: 0.0271 - accuracy: 0.9938 - val_loss: 1.5463 - val_accuracy: 0.6998 - lr: 0.0025\n",
      "Epoch 42/50\n",
      "225/225 [==============================] - 25s 111ms/step - loss: 0.0262 - accuracy: 0.9940 - val_loss: 1.4908 - val_accuracy: 0.7020 - lr: 0.0025\n",
      "Epoch 43/50\n",
      "225/225 [==============================] - 25s 113ms/step - loss: 0.0270 - accuracy: 0.9936 - val_loss: 1.5183 - val_accuracy: 0.6927 - lr: 0.0025\n",
      "Epoch 44/50\n",
      "225/225 [==============================] - 25s 111ms/step - loss: 0.0242 - accuracy: 0.9947 - val_loss: 1.5740 - val_accuracy: 0.7025 - lr: 0.0025\n",
      "Epoch 45/50\n",
      "225/225 [==============================] - 25s 110ms/step - loss: 0.0238 - accuracy: 0.9950 - val_loss: 1.5275 - val_accuracy: 0.6976 - lr: 0.0025\n",
      "Epoch 46/50\n",
      "225/225 [==============================] - 25s 110ms/step - loss: 0.0232 - accuracy: 0.9948 - val_loss: 1.5721 - val_accuracy: 0.6969 - lr: 0.0025\n",
      "Epoch 47/50\n",
      "225/225 [==============================] - 25s 110ms/step - loss: 0.0207 - accuracy: 0.9954 - val_loss: 1.5515 - val_accuracy: 0.7000 - lr: 0.0012\n",
      "Epoch 48/50\n",
      "225/225 [==============================] - 25s 112ms/step - loss: 0.0177 - accuracy: 0.9959 - val_loss: 1.5582 - val_accuracy: 0.7000 - lr: 0.0012\n",
      "Epoch 49/50\n",
      "225/225 [==============================] - 25s 110ms/step - loss: 0.0179 - accuracy: 0.9955 - val_loss: 1.5506 - val_accuracy: 0.7034 - lr: 0.0012\n",
      "Epoch 50/50\n",
      "225/225 [==============================] - 25s 112ms/step - loss: 0.0172 - accuracy: 0.9962 - val_loss: 1.5864 - val_accuracy: 0.7054 - lr: 0.0012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7eff43398ed0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau\n",
    "training_generator = ImageSequence(x_train, y_train, 128)\n",
    "validation_generator = ImageSequence(x_test, y_test, 128)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=0.0001)\n",
    "model.fit(training_generator, epochs=50, validation_data=validation_generator, callbacks=[reduce_lr]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c602ec-366e-43b1-8d77-80cd7be6435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('fer_ckplus_kdef_alexnet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
